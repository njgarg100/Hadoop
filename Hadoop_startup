Commands to run in Hadoop - 

1. start-all.sh - starts all the resources 
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [anuj-X550LD]
Starting resourcemanager
Starting nodemanagers

2. http://localhost:9870  - check the localhost whether the hadoop is up or not

3. haddop fs -mkdir -p <directory path>   - to make a directory in hadoop cluster
   hdfs dfs -mkdir -p <directory path>
   hdfs dfs -mkdir -p <directory path1> <directory path2>  - can make multiple directories

4. hadoop fs -ls <args>

5. hdfs dfs -put <local> <remote>

6. hdfs dfs -get <remote> <local folder having permissions>

7. hdfs dfs -cat <remote>

8. hdfs dfs -cp <source> <dest>

9. hdfs dfs -copyFromLocal <local> URI

10. hdfs dfs -copyToLocal URI <local>

11. hdfs dfs -mv <src> <dest>

12. hdfs dfs -rm <arg>

13. hdfs dfs -rmr <arg>

14. hdfs dfs -tail <path[filename]>  - Display the last few lines of a file

15. hdfs dfs -du <path> - displat the aggregate length of the file

16. 










